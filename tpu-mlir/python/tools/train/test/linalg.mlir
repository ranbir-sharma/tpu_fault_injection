#loc = loc(unknown)
#loc2 = loc("var_1")
#loc11 = loc("view_7")
#loc18 = loc("var")
#loc19 = loc("primals_13")
#loc23 = loc("add")
#loc47 = loc("amax")
#loc57 = loc("add_2")
#loc60 = loc("add_3")
#map = affine_map<(d0, d1, d2) -> (d0, d1, d2)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, 0)>
module @"0_main_mod_fwd" attributes {module.chip = "bm1690", module.platform = "TORCH", module.state = "TOSA_F32", module.train = "true", module.weight_file = "graph_for_jit_0_main_mod_fwd.npz"} {
  func.func @main(%arg0: tensor<30xf32> loc(unknown), %arg1: tensor<10x30xf32> loc(unknown), %arg2: tensor<10xf32> loc(unknown), %arg3: tensor<10x10xf32> loc(unknown), %arg4: tensor<40xf32> loc(unknown), %arg5: tensor<10x40xf32> loc(unknown), %arg6: tensor<10xf32> loc(unknown), %arg7: tensor<40x10xf32> loc(unknown), %arg8: tensor<10xf32> loc(unknown), %arg9: tensor<10xf32> loc(unknown), %arg10: tensor<10xf32> loc(unknown), %arg11: tensor<10xf32> loc(unknown), %arg12: tensor<1x4x10xf32> loc(unknown)) -> (tensor<f32>, tensor<2x5x4xf32>, tensor<10x30xf32>, tensor<1x4x1xf32>, tensor<1x2x4x4xf32>, tensor<4x40xf32>, tensor<2x4x5xf32>, tensor<40x10xf32>, tensor<4x10xf32>, tensor<1x4x1xf32>, tensor<1x4x1xf32>, tensor<1x4x10xf32>, tensor<1x4x10xf32>, tensor<2x4x4xf32>, tensor<2x4x5xf32>, tensor<4x10xf32>, tensor<1x4x1xf32>, tensor<10x10xf32>, tensor<4x10xf32>, tensor<10xf32>, tensor<10x40xf32>, tensor<1x4x40xf32>) {
    %cst = arith.constant 0.000000e+00 : f32 loc(#loc1)
    %c1 = arith.constant 1 : index loc(#loc2)
    %c4 = arith.constant 4 : index loc(#loc2)
    %c10 = arith.constant 10 : index loc(#loc2)
    %cst_0 = arith.constant dense<[1, 4, 1]> : tensor<3xindex> loc(#loc3)
    %cst_1 = arith.constant dense<[1, 4]> : tensor<2xindex> loc(#loc4)
    %cst_2 = arith.constant dense<[4, 10]> : tensor<2xindex> loc(#loc5)
    %cst_3 = arith.constant dense<[1, 4, 30]> : tensor<3xindex> loc(#loc6)
    %c0 = arith.constant 0 : index loc(#loc7)
    %c20 = arith.constant 20 : index loc(#loc7)
    %cst_4 = arith.constant dense<[1, 4, 2, 5]> : tensor<4xindex> loc(#loc8)
    %cst_5 = arith.constant dense<[2, 4, 5]> : tensor<3xindex> loc(#loc9)
    %cst_6 = arith.constant dense<[2, 5, 4]> : tensor<3xindex> loc(#loc10)
    %cst_7 = arith.constant dense<[1, 2, 4, 4]> : tensor<4xindex> loc(#loc11)
    %cst_8 = arith.constant dense<[1, 2, 4]> : tensor<3xindex> loc(#loc12)
    %cst_9 = arith.constant dense<[2, 4, 4]> : tensor<3xindex> loc(#loc13)
    %cst_10 = arith.constant dense<[1, 2, 4, 5]> : tensor<4xindex> loc(#loc14)
    %cst_11 = arith.constant dense<[1, 4, 10]> : tensor<3xindex> loc(#loc15)
    %cst_12 = arith.constant dense<[1, 4, 40]> : tensor<3xindex> loc(#loc16)
    %cst_13 = arith.constant dense<[4, 40]> : tensor<2xindex> loc(#loc17)
    %0 = "top.None"() : () -> none loc(#loc)
    %1 = tensor.empty(%c1, %c4, %c10) : tensor<?x?x?xf32> loc(#loc18)
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<?x?x?xf32>) -> tensor<?x?x?xf32> loc(#loc18)
    %3 = linalg.generic {indexing_maps = [#map, #map], iterator_types = ["parallel", "parallel", "parallel"]} ins(%arg12 : tensor<1x4x10xf32>) outs(%2 : tensor<?x?x?xf32>) {
    ^bb0(%in: f32 loc("primals_13"), %out: f32 loc("var")):
      %109 = arith.addf %in, %out : f32 loc(#loc18)
      linalg.yield %109 : f32 loc(#loc18)
    } -> tensor<?x?x?xf32> loc(#loc18)
    %4 = tensor.empty() : tensor<1x4xf32> loc(#loc20)
    %reduced = linalg.reduce { arith.addf } ins(%arg12 : tensor<1x4x10xf32>) outs(%4 : tensor<1x4xf32>) dimensions = [2]  loc(#loc20)
    %reshape = tensor.reshape %3(%cst_0) : (tensor<?x?x?xf32>, tensor<3xindex>) -> tensor<1x4x1xf32> loc(#loc21)
    %reshape_14 = tensor.reshape %reduced(%cst_0) : (tensor<1x4xf32>, tensor<3xindex>) -> tensor<1x4x1xf32> loc(#loc22)
    %5 = tensor.empty() : tensor<1x4x1xf32> loc(#loc23)
    %6 = "top.Weight"() : () -> tensor<1xf32> loc(#loc24)
    %7 = tensor.empty() : tensor<1x4x1xf32> loc(#loc23)
    %broadcasted = linalg.broadcast ins(%6 : tensor<1xf32>) outs(%7 : tensor<1x4x1xf32>) dimensions = [1, 2]  loc(#loc23)
    %8 = linalg.add ins(%reshape, %broadcasted : tensor<1x4x1xf32>, tensor<1x4x1xf32>) outs(%5 : tensor<1x4x1xf32>) -> tensor<1x4x1xf32> loc(#loc23)
    %9 = "top.Weight"() : () -> tensor<1xf32> loc(#loc25)
    %10 = "top.Weight"() : () -> tensor<1xf32> loc(#loc26)
    %11 = tensor.empty() : tensor<1x4x1xf32> loc(#loc27)
    %12 = "top.Weight"() : () -> tensor<1xf32> loc(#loc28)
    %13 = tensor.empty() : tensor<1x4x1xf32> loc(#loc27)
    %broadcasted_15 = linalg.broadcast ins(%12 : tensor<1xf32>) outs(%13 : tensor<1x4x1xf32>) dimensions = [1, 2]  loc(#loc27)
    %14 = linalg.mul ins(%reshape_14, %broadcasted_15 : tensor<1x4x1xf32>, tensor<1x4x1xf32>) outs(%11 : tensor<1x4x1xf32>) -> tensor<1x4x1xf32> loc(#loc27)
    %15 = linalg.generic {indexing_maps = [#map, #map], iterator_types = ["parallel", "parallel", "parallel"]} ins(%8 : tensor<1x4x1xf32>) outs(%8 : tensor<1x4x1xf32>) {
    ^bb0(%in: f32 loc("add"), %out: f32 loc("add")):
      %109 = math.sqrt %in : f32 loc(#loc29)
      linalg.yield %109 : f32 loc(#loc29)
    } -> tensor<1x4x1xf32> loc(#loc29)
    %16 = tensor.empty() : tensor<1x4x10xf32> loc(#loc30)
    %reshape_16 = tensor.reshape %14(%cst_1) : (tensor<1x4x1xf32>, tensor<2xindex>) -> tensor<1x4xf32> loc(#loc30)
    %17 = tensor.empty() : tensor<1x4x10xf32> loc(#loc30)
    %broadcasted_17 = linalg.broadcast ins(%reshape_16 : tensor<1x4xf32>) outs(%17 : tensor<1x4x10xf32>) dimensions = [2]  loc(#loc30)
    %18 = linalg.sub ins(%arg12, %broadcasted_17 : tensor<1x4x10xf32>, tensor<1x4x10xf32>) outs(%16 : tensor<1x4x10xf32>) -> tensor<1x4x10xf32> loc(#loc30)
    %19 = tensor.empty() : tensor<1x4x10xf32> loc(#loc31)
    %reshape_18 = tensor.reshape %15(%cst_1) : (tensor<1x4x1xf32>, tensor<2xindex>) -> tensor<1x4xf32> loc(#loc31)
    %20 = tensor.empty() : tensor<1x4x10xf32> loc(#loc31)
    %broadcasted_19 = linalg.broadcast ins(%reshape_18 : tensor<1x4xf32>) outs(%20 : tensor<1x4x10xf32>) dimensions = [2]  loc(#loc31)
    %21 = linalg.mul ins(%18, %broadcasted_19 : tensor<1x4x10xf32>, tensor<1x4x10xf32>) outs(%19 : tensor<1x4x10xf32>) -> tensor<1x4x10xf32> loc(#loc31)
    %22 = tensor.empty() : tensor<1x4x10xf32> loc(#loc32)
    %23 = tensor.empty() : tensor<1x4x10xf32> loc(#loc32)
    %broadcasted_20 = linalg.broadcast ins(%arg8 : tensor<10xf32>) outs(%23 : tensor<1x4x10xf32>) dimensions = [0, 1]  loc(#loc32)
    %24 = linalg.mul ins(%21, %broadcasted_20 : tensor<1x4x10xf32>, tensor<1x4x10xf32>) outs(%22 : tensor<1x4x10xf32>) -> tensor<1x4x10xf32> loc(#loc32)
    %25 = tensor.empty() : tensor<1x4x10xf32> loc(#loc33)
    %26 = tensor.empty() : tensor<1x4x10xf32> loc(#loc33)
    %broadcasted_21 = linalg.broadcast ins(%arg9 : tensor<10xf32>) outs(%26 : tensor<1x4x10xf32>) dimensions = [0, 1]  loc(#loc33)
    %27 = linalg.add ins(%24, %broadcasted_21 : tensor<1x4x10xf32>, tensor<1x4x10xf32>) outs(%25 : tensor<1x4x10xf32>) -> tensor<1x4x10xf32> loc(#loc33)
    %reshape_22 = tensor.reshape %27(%cst_2) : (tensor<1x4x10xf32>, tensor<2xindex>) -> tensor<4x10xf32> loc(#loc34)
    %28 = tensor.empty() : tensor<4x30xf32> loc(#loc35)
    %29 = linalg.fill ins(%cst : f32) outs(%28 : tensor<4x30xf32>) -> tensor<4x30xf32> loc(#loc35)
    %30 = linalg.matmul ins(%reshape_22, %arg1 : tensor<4x10xf32>, tensor<10x30xf32>) outs(%29 : tensor<4x30xf32>) -> tensor<4x30xf32> loc(#loc35)
    %31 = tensor.empty() : tensor<4x30xf32> loc(#loc36)
    %32 = tensor.empty() : tensor<4x30xf32> loc(#loc36)
    %broadcasted_23 = linalg.broadcast ins(%arg0 : tensor<30xf32>) outs(%32 : tensor<4x30xf32>) dimensions = [0]  loc(#loc36)
    %33 = linalg.add ins(%broadcasted_23, %30 : tensor<4x30xf32>, tensor<4x30xf32>) outs(%31 : tensor<4x30xf32>) -> tensor<4x30xf32> loc(#loc36)
    %reshape_24 = tensor.reshape %33(%cst_3) : (tensor<4x30xf32>, tensor<3xindex>) -> tensor<1x4x30xf32> loc(#loc6)
    %extracted_slice = tensor.extract_slice %reshape_24[%c0, %c0, %c0] [%c1, %c4, %c10] [%c1, %c1, %c1] : tensor<1x4x30xf32> to tensor<?x?x?xf32> loc(#loc37)
    %extracted_slice_25 = tensor.extract_slice %reshape_24[%c0, %c0, %c10] [%c1, %c4, %c10] [%c1, %c1, %c1] : tensor<1x4x30xf32> to tensor<?x?x?xf32> loc(#loc38)
    %extracted_slice_26 = tensor.extract_slice %reshape_24[%c0, %c0, %c20] [%c1, %c4, %c10] [%c1, %c1, %c1] : tensor<1x4x30xf32> to tensor<?x?x?xf32> loc(#loc7)
    %reshape_27 = tensor.reshape %extracted_slice(%cst_4) : (tensor<?x?x?xf32>, tensor<4xindex>) -> tensor<1x4x2x5xf32> loc(#loc39)
    %reshape_28 = tensor.reshape %extracted_slice_25(%cst_4) : (tensor<?x?x?xf32>, tensor<4xindex>) -> tensor<1x4x2x5xf32> loc(#loc40)
    %reshape_29 = tensor.reshape %extracted_slice_26(%cst_4) : (tensor<?x?x?xf32>, tensor<4xindex>) -> tensor<1x4x2x5xf32> loc(#loc8)
    %34 = tensor.empty() : tensor<1x2x4x5xf32> loc(#loc41)
    %transposed = linalg.transpose ins(%reshape_27 : tensor<1x4x2x5xf32>) outs(%34 : tensor<1x2x4x5xf32>) permutation = [0, 2, 1, 3]  loc(#loc41)
    %35 = tensor.empty() : tensor<1x2x4x5xf32> loc(#loc42)
    %transposed_30 = linalg.transpose ins(%reshape_28 : tensor<1x4x2x5xf32>) outs(%35 : tensor<1x2x4x5xf32>) permutation = [0, 2, 1, 3]  loc(#loc42)
    %36 = tensor.empty() : tensor<1x2x4x5xf32> loc(#loc43)
    %transposed_31 = linalg.transpose ins(%reshape_29 : tensor<1x4x2x5xf32>) outs(%36 : tensor<1x2x4x5xf32>) permutation = [0, 2, 1, 3]  loc(#loc43)
    %reshape_32 = tensor.reshape %transposed(%cst_5) : (tensor<1x2x4x5xf32>, tensor<3xindex>) -> tensor<2x4x5xf32> loc(#loc44)
    %37 = tensor.empty() : tensor<1x2x5x4xf32> loc(#loc45)
    %transposed_33 = linalg.transpose ins(%transposed_30 : tensor<1x2x4x5xf32>) outs(%37 : tensor<1x2x5x4xf32>) permutation = [0, 1, 3, 2]  loc(#loc45)
    %reshape_34 = tensor.reshape %transposed_31(%cst_5) : (tensor<1x2x4x5xf32>, tensor<3xindex>) -> tensor<2x4x5xf32> loc(#loc9)
    %reshape_35 = tensor.reshape %transposed_33(%cst_6) : (tensor<1x2x5x4xf32>, tensor<3xindex>) -> tensor<2x5x4xf32> loc(#loc10)
    %38 = tensor.empty() : tensor<2x4x4xf32> loc(#loc46)
    %39 = linalg.fill ins(%cst : f32) outs(%38 : tensor<2x4x4xf32>) -> tensor<2x4x4xf32> loc(#loc46)
    %40 = linalg.batch_matmul ins(%reshape_32, %reshape_35 : tensor<2x4x5xf32>, tensor<2x5x4xf32>) outs(%39 : tensor<2x4x4xf32>) -> tensor<2x4x4xf32> loc(#loc46)
    %reshape_36 = tensor.reshape %40(%cst_7) : (tensor<2x4x4xf32>, tensor<4xindex>) -> tensor<1x2x4x4xf32> loc(#loc11)
    %41 = tensor.empty() : tensor<1x2x4x1xf32> loc(#loc47)
    %42 = linalg.fill ins(%cst : f32) outs(%41 : tensor<1x2x4x1xf32>) -> tensor<1x2x4x1xf32> loc(#loc47)
    %43 = tensor.empty() : tensor<1x2x4x1xf32> loc(#loc47)
    %44 = linalg.fill ins(%cst : f32) outs(%43 : tensor<1x2x4x1xf32>) -> tensor<1x2x4x1xf32> loc(#loc47)
    %45:2 = linalg.generic {indexing_maps = [#map1, #map2, #map2], iterator_types = ["parallel", "parallel", "parallel", "reduction"]} ins(%reshape_36 : tensor<1x2x4x4xf32>) outs(%44, %42 : tensor<1x2x4x1xf32>, tensor<1x2x4x1xf32>) {
    ^bb0(%in: f32 loc("view_7"), %out: f32 loc("amax"), %out_66: f32 loc("amax")):
      %109 = linalg.index 3 : index loc(#loc47)
      %110 = arith.index_cast %109 : index to i32 loc(#loc47)
      %111 = arith.sitofp %110 : i32 to f32 loc(#loc47)
      %112 = arith.maxf %in, %out : f32 loc(#loc47)
      %113 = arith.cmpf ogt, %in, %out : f32 loc(#loc47)
      %114 = arith.select %113, %111, %out_66 : f32 loc(#loc47)
      linalg.yield %112, %114 : f32, f32 loc(#loc47)
    } -> (tensor<1x2x4x1xf32>, tensor<1x2x4x1xf32>) loc(#loc47)
    %46 = tensor.empty() : tensor<1x2x4x4xf32> loc(#loc48)
    %reshape_37 = tensor.reshape %45#1(%cst_8) : (tensor<1x2x4x1xf32>, tensor<3xindex>) -> tensor<1x2x4xf32> loc(#loc48)
    %47 = tensor.empty() : tensor<1x2x4x4xf32> loc(#loc48)
    %broadcasted_38 = linalg.broadcast ins(%reshape_37 : tensor<1x2x4xf32>) outs(%47 : tensor<1x2x4x4xf32>) dimensions = [3]  loc(#loc48)
    %48 = linalg.sub ins(%reshape_36, %broadcasted_38 : tensor<1x2x4x4xf32>, tensor<1x2x4x4xf32>) outs(%46 : tensor<1x2x4x4xf32>) -> tensor<1x2x4x4xf32> loc(#loc48)
    %49 = tensor.empty() : tensor<1x2x4x4xf32> loc(#loc49)
    %50 = linalg.exp ins(%48 : tensor<1x2x4x4xf32>) outs(%49 : tensor<1x2x4x4xf32>) -> tensor<1x2x4x4xf32> loc(#loc49)
    %51 = tensor.empty() : tensor<1x2x4xf32> loc(#loc50)
    %reduced_39 = linalg.reduce { arith.addf } ins(%50 : tensor<1x2x4x4xf32>) outs(%51 : tensor<1x2x4xf32>) dimensions = [3]  loc(#loc50)
    %52 = tensor.empty() : tensor<1x2x4x4xf32> loc(#loc12)
    %reshape_40 = tensor.reshape %reduced_39(%cst_8) : (tensor<1x2x4xf32>, tensor<3xindex>) -> tensor<1x2x4xf32> loc(#loc12)
    %53 = tensor.empty() : tensor<1x2x4x4xf32> loc(#loc12)
    %broadcasted_41 = linalg.broadcast ins(%reshape_40 : tensor<1x2x4xf32>) outs(%53 : tensor<1x2x4x4xf32>) dimensions = [3]  loc(#loc12)
    %54 = linalg.div ins(%50, %broadcasted_41 : tensor<1x2x4x4xf32>, tensor<1x2x4x4xf32>) outs(%52 : tensor<1x2x4x4xf32>) -> tensor<1x2x4x4xf32> loc(#loc12)
    %reshape_42 = tensor.reshape %54(%cst_9) : (tensor<1x2x4x4xf32>, tensor<3xindex>) -> tensor<2x4x4xf32> loc(#loc13)
    %55 = tensor.empty() : tensor<2x4x5xf32> loc(#loc51)
    %56 = linalg.fill ins(%cst : f32) outs(%55 : tensor<2x4x5xf32>) -> tensor<2x4x5xf32> loc(#loc51)
    %57 = linalg.batch_matmul ins(%reshape_42, %reshape_34 : tensor<2x4x4xf32>, tensor<2x4x5xf32>) outs(%56 : tensor<2x4x5xf32>) -> tensor<2x4x5xf32> loc(#loc51)
    %reshape_43 = tensor.reshape %57(%cst_10) : (tensor<2x4x5xf32>, tensor<4xindex>) -> tensor<1x2x4x5xf32> loc(#loc14)
    %58 = tensor.empty() : tensor<1x4x2x5xf32> loc(#loc52)
    %transposed_44 = linalg.transpose ins(%reshape_43 : tensor<1x2x4x5xf32>) outs(%58 : tensor<1x4x2x5xf32>) permutation = [0, 2, 1, 3]  loc(#loc52)
    %reshape_45 = tensor.reshape %transposed_44(%cst_2) : (tensor<1x4x2x5xf32>, tensor<2xindex>) -> tensor<4x10xf32> loc(#loc53)
    %59 = tensor.empty() : tensor<4x10xf32> loc(#loc54)
    %60 = linalg.fill ins(%cst : f32) outs(%59 : tensor<4x10xf32>) -> tensor<4x10xf32> loc(#loc54)
    %61 = linalg.matmul ins(%reshape_45, %arg3 : tensor<4x10xf32>, tensor<10x10xf32>) outs(%60 : tensor<4x10xf32>) -> tensor<4x10xf32> loc(#loc54)
    %62 = tensor.empty() : tensor<4x10xf32> loc(#loc55)
    %63 = tensor.empty() : tensor<4x10xf32> loc(#loc55)
    %broadcasted_46 = linalg.broadcast ins(%arg2 : tensor<10xf32>) outs(%63 : tensor<4x10xf32>) dimensions = [0]  loc(#loc55)
    %64 = linalg.add ins(%broadcasted_46, %61 : tensor<4x10xf32>, tensor<4x10xf32>) outs(%62 : tensor<4x10xf32>) -> tensor<4x10xf32> loc(#loc55)
    %reshape_47 = tensor.reshape %64(%cst_11) : (tensor<4x10xf32>, tensor<3xindex>) -> tensor<1x4x10xf32> loc(#loc56)
    %65 = tensor.empty() : tensor<1x4x10xf32> loc(#loc57)
    %66 = linalg.add ins(%arg12, %reshape_47 : tensor<1x4x10xf32>, tensor<1x4x10xf32>) outs(%65 : tensor<1x4x10xf32>) -> tensor<1x4x10xf32> loc(#loc57)
    %67 = tensor.empty(%c1, %c4, %c10) : tensor<?x?x?xf32> loc(#loc2)
    %68 = linalg.fill ins(%cst : f32) outs(%67 : tensor<?x?x?xf32>) -> tensor<?x?x?xf32> loc(#loc2)
    %69 = linalg.generic {indexing_maps = [#map, #map], iterator_types = ["parallel", "parallel", "parallel"]} ins(%66 : tensor<1x4x10xf32>) outs(%68 : tensor<?x?x?xf32>) {
    ^bb0(%in: f32 loc("add_2"), %out: f32 loc("var_1")):
      %109 = arith.addf %in, %out : f32 loc(#loc2)
      linalg.yield %109 : f32 loc(#loc2)
    } -> tensor<?x?x?xf32> loc(#loc2)
    %70 = tensor.empty() : tensor<1x4xf32> loc(#loc58)
    %reduced_48 = linalg.reduce { arith.addf } ins(%66 : tensor<1x4x10xf32>) outs(%70 : tensor<1x4xf32>) dimensions = [2]  loc(#loc58)
    %reshape_49 = tensor.reshape %69(%cst_0) : (tensor<?x?x?xf32>, tensor<3xindex>) -> tensor<1x4x1xf32> loc(#loc59)
    %reshape_50 = tensor.reshape %reduced_48(%cst_0) : (tensor<1x4xf32>, tensor<3xindex>) -> tensor<1x4x1xf32> loc(#loc3)
    %71 = tensor.empty() : tensor<1x4x1xf32> loc(#loc60)
    %72 = "top.Weight"() : () -> tensor<1xf32> loc(#loc61)
    %73 = tensor.empty() : tensor<1x4x1xf32> loc(#loc60)
    %broadcasted_51 = linalg.broadcast ins(%72 : tensor<1xf32>) outs(%73 : tensor<1x4x1xf32>) dimensions = [1, 2]  loc(#loc60)
    %74 = linalg.add ins(%reshape_49, %broadcasted_51 : tensor<1x4x1xf32>, tensor<1x4x1xf32>) outs(%71 : tensor<1x4x1xf32>) -> tensor<1x4x1xf32> loc(#loc60)
    %75 = "top.Weight"() : () -> tensor<1xf32> loc(#loc62)
    %76 = "top.Weight"() : () -> tensor<1xf32> loc(#loc63)
    %77 = tensor.empty() : tensor<1x4x1xf32> loc(#loc64)
    %78 = "top.Weight"() : () -> tensor<1xf32> loc(#loc65)
    %79 = tensor.empty() : tensor<1x4x1xf32> loc(#loc64)
    %broadcasted_52 = linalg.broadcast ins(%78 : tensor<1xf32>) outs(%79 : tensor<1x4x1xf32>) dimensions = [1, 2]  loc(#loc64)
    %80 = linalg.mul ins(%reshape_50, %broadcasted_52 : tensor<1x4x1xf32>, tensor<1x4x1xf32>) outs(%77 : tensor<1x4x1xf32>) -> tensor<1x4x1xf32> loc(#loc64)
    %81 = linalg.generic {indexing_maps = [#map, #map], iterator_types = ["parallel", "parallel", "parallel"]} ins(%74 : tensor<1x4x1xf32>) outs(%74 : tensor<1x4x1xf32>) {
    ^bb0(%in: f32 loc("add_3"), %out: f32 loc("add_3")):
      %109 = math.sqrt %in : f32 loc(#loc66)
      linalg.yield %109 : f32 loc(#loc66)
    } -> tensor<1x4x1xf32> loc(#loc66)
    %82 = tensor.empty() : tensor<1x4x10xf32> loc(#loc67)
    %reshape_53 = tensor.reshape %80(%cst_1) : (tensor<1x4x1xf32>, tensor<2xindex>) -> tensor<1x4xf32> loc(#loc67)
    %83 = tensor.empty() : tensor<1x4x10xf32> loc(#loc67)
    %broadcasted_54 = linalg.broadcast ins(%reshape_53 : tensor<1x4xf32>) outs(%83 : tensor<1x4x10xf32>) dimensions = [2]  loc(#loc67)
    %84 = linalg.sub ins(%66, %broadcasted_54 : tensor<1x4x10xf32>, tensor<1x4x10xf32>) outs(%82 : tensor<1x4x10xf32>) -> tensor<1x4x10xf32> loc(#loc67)
    %85 = tensor.empty() : tensor<1x4x10xf32> loc(#loc4)
    %reshape_55 = tensor.reshape %81(%cst_1) : (tensor<1x4x1xf32>, tensor<2xindex>) -> tensor<1x4xf32> loc(#loc4)
    %86 = tensor.empty() : tensor<1x4x10xf32> loc(#loc4)
    %broadcasted_56 = linalg.broadcast ins(%reshape_55 : tensor<1x4xf32>) outs(%86 : tensor<1x4x10xf32>) dimensions = [2]  loc(#loc4)
    %87 = linalg.mul ins(%84, %broadcasted_56 : tensor<1x4x10xf32>, tensor<1x4x10xf32>) outs(%85 : tensor<1x4x10xf32>) -> tensor<1x4x10xf32> loc(#loc4)
    %88 = tensor.empty() : tensor<1x4x10xf32> loc(#loc68)
    %89 = tensor.empty() : tensor<1x4x10xf32> loc(#loc68)
    %broadcasted_57 = linalg.broadcast ins(%arg10 : tensor<10xf32>) outs(%89 : tensor<1x4x10xf32>) dimensions = [0, 1]  loc(#loc68)
    %90 = linalg.mul ins(%87, %broadcasted_57 : tensor<1x4x10xf32>, tensor<1x4x10xf32>) outs(%88 : tensor<1x4x10xf32>) -> tensor<1x4x10xf32> loc(#loc68)
    %91 = tensor.empty() : tensor<1x4x10xf32> loc(#loc69)
    %92 = tensor.empty() : tensor<1x4x10xf32> loc(#loc69)
    %broadcasted_58 = linalg.broadcast ins(%arg11 : tensor<10xf32>) outs(%92 : tensor<1x4x10xf32>) dimensions = [0, 1]  loc(#loc69)
    %93 = linalg.add ins(%90, %broadcasted_58 : tensor<1x4x10xf32>, tensor<1x4x10xf32>) outs(%91 : tensor<1x4x10xf32>) -> tensor<1x4x10xf32> loc(#loc69)
    %reshape_59 = tensor.reshape %93(%cst_2) : (tensor<1x4x10xf32>, tensor<2xindex>) -> tensor<4x10xf32> loc(#loc5)
    %94 = tensor.empty() : tensor<4x40xf32> loc(#loc70)
    %95 = linalg.fill ins(%cst : f32) outs(%94 : tensor<4x40xf32>) -> tensor<4x40xf32> loc(#loc70)
    %96 = linalg.matmul ins(%reshape_59, %arg5 : tensor<4x10xf32>, tensor<10x40xf32>) outs(%95 : tensor<4x40xf32>) -> tensor<4x40xf32> loc(#loc70)
    %97 = tensor.empty() : tensor<4x40xf32> loc(#loc71)
    %98 = tensor.empty() : tensor<4x40xf32> loc(#loc71)
    %broadcasted_60 = linalg.broadcast ins(%arg4 : tensor<40xf32>) outs(%98 : tensor<4x40xf32>) dimensions = [0]  loc(#loc71)
    %99 = linalg.add ins(%broadcasted_60, %96 : tensor<4x40xf32>, tensor<4x40xf32>) outs(%97 : tensor<4x40xf32>) -> tensor<4x40xf32> loc(#loc71)
    %reshape_61 = tensor.reshape %99(%cst_12) : (tensor<4x40xf32>, tensor<3xindex>) -> tensor<1x4x40xf32> loc(#loc16)
    %reshape_62 = tensor.reshape %reshape_61(%cst_13) : (tensor<1x4x40xf32>, tensor<2xindex>) -> tensor<4x40xf32> loc(#loc17)
    %100 = tensor.empty() : tensor<4x10xf32> loc(#loc1)
    %101 = linalg.fill ins(%cst : f32) outs(%100 : tensor<4x10xf32>) -> tensor<4x10xf32> loc(#loc1)
    %102 = linalg.matmul ins(%reshape_62, %arg7 : tensor<4x40xf32>, tensor<40x10xf32>) outs(%101 : tensor<4x10xf32>) -> tensor<4x10xf32> loc(#loc1)
    %103 = tensor.empty() : tensor<4x10xf32> loc(#loc72)
    %104 = tensor.empty() : tensor<4x10xf32> loc(#loc72)
    %broadcasted_63 = linalg.broadcast ins(%arg6 : tensor<10xf32>) outs(%104 : tensor<4x10xf32>) dimensions = [0]  loc(#loc72)
    %105 = linalg.add ins(%broadcasted_63, %102 : tensor<4x10xf32>, tensor<4x10xf32>) outs(%103 : tensor<4x10xf32>) -> tensor<4x10xf32> loc(#loc72)
    %reshape_64 = tensor.reshape %105(%cst_11) : (tensor<4x10xf32>, tensor<3xindex>) -> tensor<1x4x10xf32> loc(#loc15)
    %106 = tensor.empty() : tensor<1x4x10xf32> loc(#loc73)
    %107 = linalg.add ins(%66, %reshape_64 : tensor<1x4x10xf32>, tensor<1x4x10xf32>) outs(%106 : tensor<1x4x10xf32>) -> tensor<1x4x10xf32> loc(#loc73)
    %108 = tensor.empty() : tensor<f32> loc(#loc74)
    %reduced_65 = linalg.reduce { arith.addf } ins(%107 : tensor<1x4x10xf32>) outs(%108 : tensor<f32>) dimensions = [0, 1, 2]  loc(#loc74)
    return %reduced_65, %reshape_35, %arg1, %14, %54, %reshape_62, %reshape_34, %arg7, %reshape_22, %15, %81, %66, %arg12, %reshape_42, %reshape_32, %reshape_59, %80, %arg3, %reshape_45, %arg10, %arg5, %reshape_61 : tensor<f32>, tensor<2x5x4xf32>, tensor<10x30xf32>, tensor<1x4x1xf32>, tensor<1x2x4x4xf32>, tensor<4x40xf32>, tensor<2x4x5xf32>, tensor<40x10xf32>, tensor<4x10xf32>, tensor<1x4x1xf32>, tensor<1x4x1xf32>, tensor<1x4x10xf32>, tensor<1x4x10xf32>, tensor<2x4x4xf32>, tensor<2x4x5xf32>, tensor<4x10xf32>, tensor<1x4x1xf32>, tensor<10x10xf32>, tensor<4x10xf32>, tensor<10xf32>, tensor<10x40xf32>, tensor<1x4x40xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc1 = loc("addmm_3_mm")
#loc3 = loc("broadcast_in_dim_3_unsqueeze")
#loc4 = loc("mul_2")
#loc5 = loc("view_14")
#loc6 = loc("view_1")
#loc7 = loc("split_2")
#loc8 = loc("view_4")
#loc9 = loc("view_9")
#loc10 = loc("view_6")
#loc12 = loc("div_1")
#loc13 = loc("view_8")
#loc14 = loc("view_10")
#loc15 = loc("view_17")
#loc16 = loc("addmm_2_top.Relu_top.Reshape")
#loc17 = loc("view_16")
#loc20 = loc("sum_1")
#loc21 = loc("broadcast_in_dim_unsqueeze")
#loc22 = loc("broadcast_in_dim_1_unsqueeze")
#loc24 = loc("add_f32")
#loc25 = loc("divOp_div_input2")
#loc26 = loc("div_divisor")
#loc27 = loc("div")
#loc28 = loc("div_f32")
#loc29 = loc("rsqrt")
#loc30 = loc("sub")
#loc31 = loc("mul")
#loc32 = loc("mul_1")
#loc33 = loc("add_1")
#loc34 = loc("view")
#loc35 = loc("addmm_mm")
#loc36 = loc("addmm")
#loc37 = loc("split_0")
#loc38 = loc("split_1")
#loc39 = loc("view_2")
#loc40 = loc("view_3")
#loc41 = loc("permute")
#loc42 = loc("permute_1")
#loc43 = loc("permute_2")
#loc44 = loc("view_5")
#loc45 = loc("permute_3")
#loc46 = loc("bmm")
#loc48 = loc("sub_1")
#loc49 = loc("exp")
#loc50 = loc("sum_2")
#loc51 = loc("bmm_1")
#loc52 = loc("permute_4")
#loc53 = loc("view_12")
#loc54 = loc("addmm_1_mm")
#loc55 = loc("addmm_1")
#loc56 = loc("view_13")
#loc58 = loc("sum_3")
#loc59 = loc("broadcast_in_dim_2_unsqueeze")
#loc61 = loc("add_3_f32")
#loc62 = loc("divOp_div_2_input2")
#loc63 = loc("div_2_divisor")
#loc64 = loc("div_2")
#loc65 = loc("div_2_f32")
#loc66 = loc("rsqrt_1")
#loc67 = loc("sub_2")
#loc68 = loc("mul_3")
#loc69 = loc("add_4")
#loc70 = loc("addmm_2_mm")
#loc71 = loc("addmm_2_top.Relu")
#loc72 = loc("addmm_3")
#loc73 = loc("add_5")
#loc74 = loc("sum_4")

